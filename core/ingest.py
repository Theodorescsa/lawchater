import os
import shutil
from pathlib import Path
from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, DirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings 
from langchain_chroma import Chroma

os.environ["ANONYMIZED_TELEMETRY"] = "False"

# XÃ¡c Ä‘á»‹nh Ä‘Æ°á»ng dáº«n
BASE_DIR = Path(__file__).resolve().parent
DATA_PATH = str(BASE_DIR / "data")
PERSIST_PATH = str(BASE_DIR / "chroma_db")
COLLECTION_NAME = "law_docs"
EMBEDDING_MODEL_NAME = "intfloat/multilingual-e5-small"

def main():
    print("ğŸš€ Báº¯t Ä‘áº§u náº¡p dá»¯ liá»‡u (Ingest)...")
    
    if not os.path.exists(DATA_PATH):
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y folder data táº¡i {DATA_PATH}")
        return

    # 1. Load Documents
    documents = []
    def load_docs(glob, loader_cls):
        loader = DirectoryLoader(DATA_PATH, glob=glob, loader_cls=loader_cls, show_progress=True)
        try: return loader.load()
        except: return []

    documents.extend(load_docs("**/*.pdf", PyPDFLoader))
    documents.extend(load_docs("**/*.docx", Docx2txtLoader))
    
    if not documents:
        print("âŒ Folder data rá»—ng.")
        return

    # 2. Tiá»n xá»­ lÃ½ (ThÃªm tÃªn file vÃ o ná»™i dung)
    print("ğŸ› ï¸ Äang xá»­ lÃ½ metadata...")
    for doc in documents:
        source_file = os.path.basename(doc.metadata.get('source', ''))
        doc.metadata['source_name'] = source_file
        # Gáº¯n tÃªn file vÃ o ná»™i dung Ä‘á»ƒ chunk nÃ o cÅ©ng biáº¿t mÃ¬nh thuá»™c luáº­t nÃ o
        doc.page_content = f"TÃ i liá»‡u: {source_file}\n{doc.page_content}"

    # 3. Chia nhá» (Split)
    print("âœ‚ï¸ Äang chia nhá» vÄƒn báº£n...")
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=2000, 
        chunk_overlap=200,
        separators=["\n\nÄiá»u ", "\nÄiá»u ", "Äiá»u "],
        keep_separator=True
    )
    chunks = splitter.split_documents(documents)

    # 4. ThÃªm prefix cho E5 Model
    final_chunks = []
    for chunk in chunks:
        # Báº¯t buá»™c cho model intfloat/multilingual-e5-small
        chunk.page_content = f"passage: {chunk.page_content}"
        final_chunks.append(chunk)

    # 5. Embedding & LÆ°u vÃ o ChromaDB
    print("ğŸ’¾ Äang ghi vÃ o Database...")
    embedding = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME, model_kwargs={'device': 'cpu'})
    
    # XÃ³a DB cÅ© náº¿u cÃ³ Ä‘á»ƒ lÃ m sáº¡ch
    if os.path.exists(PERSIST_PATH):
        shutil.rmtree(PERSIST_PATH)

    Chroma.from_documents(
        documents=final_chunks, 
        embedding=embedding, 
        collection_name=COLLECTION_NAME, 
        persist_directory=PERSIST_PATH
    )
    
    print(f"âœ… HoÃ n táº¥t! ÄÃ£ lÆ°u {len(final_chunks)} chunks vÃ o {PERSIST_PATH}")

if __name__ == "__main__":
    main()